H(A) = 1.0 ---> Entropia entrada
H(B) = 1.5 ---> Entropia salida
H(A,B) = 1.5 ---> Entropia afin
H(A/B) = 0.0 ---> Ruido/Equivocacion
H(B/A) = 0.5 ---> Perdida
I(A,B) = 1.0 ---> Informacion mutua
I(B,A) = 1.0 ---> Informacion mutua
Propiedades informacion mutua:
1) I(A,B) >= 0 ---> 1.0 >= 0
2) I(A,B) = I(B,A) ---> I(A,B) = 1.0 I(B,A) = 1.0 ---> 1.0 = 1.0
3) H(A,B) = H(A) + H(B) - I(A,B) ---> H(A,B) = 1.5 H(A) + H(B) - I(A,B) = 1.0 + 1.5 - 1.0 = 1.5 ---> 1.5 = 1.5